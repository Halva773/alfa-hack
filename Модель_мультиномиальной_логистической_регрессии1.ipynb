{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef22136-4c2f-4133-8318-e17971475cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame сохранен в файл: results/updated_train_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_parquet(\"Задание/train_data.pqt\")\n",
    "\n",
    "# Создаем словарь для заполнения index_city_code\n",
    "city_code_dict = df.dropna(subset=['index_city_code']).drop_duplicates('city').set_index('city')['index_city_code'].to_dict()\n",
    "\n",
    "# Функция для заполнения index_city_code на основе city\n",
    "def fill_index_city_code(row):\n",
    "    if pd.isnull(row['index_city_code']) and row['city'] in city_code_dict:\n",
    "        return city_code_dict[row['city']]\n",
    "    else:\n",
    "        return row['index_city_code']\n",
    "\n",
    "# Применяем функцию к каждой строке DataFrame\n",
    "df['index_city_code'] = df.apply(fill_index_city_code, axis=1)\n",
    "\n",
    "# Определяем столбцы для исключения из обработки\n",
    "columns_to_exclude = ['index_city_code']\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).drop(columns=columns_to_exclude, errors='ignore').columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).drop(columns=columns_to_exclude, errors='ignore').columns\n",
    "\n",
    "# Фильтруем строки, содержащие интересующие нас месяцы, и применяем операции к ним\n",
    "months = ['month_1', 'month_2', 'month_3']\n",
    "mask = df['date'].isin(months)\n",
    "if mask.any():\n",
    "    # Применяем интерполяцию ко всем числовым столбцам для отфильтрованных строк\n",
    "    df.loc[mask, numeric_columns] = df.loc[mask, numeric_columns].interpolate(method='linear')\n",
    "    \n",
    "    # Заполнение нечисловых столбцов вперёд для отфильтрованных строк\n",
    "    df.loc[mask, non_numeric_columns] = df.loc[mask, non_numeric_columns].fillna(method='ffill')\n",
    "else:\n",
    "    print('Упс, указанные месяцы не найдены в столбце \"date\".')\n",
    "\n",
    "\n",
    "\n",
    "output_file_path = \"results/updated_train_data.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f'DataFrame сохранен в файл: {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550b764a-1645-4194-8464-57f37bda8af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame сохранен в файл: results/updated_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_parquet(\"Задание/test_data.pqt\")\n",
    "\n",
    "city_code_dict = df.dropna(subset=['index_city_code']).drop_duplicates('city').set_index('city')['index_city_code'].to_dict()\n",
    "\n",
    "# Функция для заполнения index_city_code на основе city\n",
    "def fill_index_city_code(row):\n",
    "    if pd.isnull(row['index_city_code']) and row['city'] in city_code_dict:\n",
    "        return city_code_dict[row['city']]\n",
    "    else:\n",
    "        return row['index_city_code']\n",
    "\n",
    "# Применяем функцию к каждой строке DataFrame\n",
    "df['index_city_code'] = df.apply(fill_index_city_code, axis=1)\n",
    "\n",
    "# Выбор числовых столбцов, исключая 'index_city_code'\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).drop(columns=columns_to_exclude, errors='ignore').columns\n",
    "\n",
    "# Выбор нечисловых столбцов, исключая 'index_city_code'\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).drop(columns=columns_to_exclude, errors='ignore').columns\n",
    "\n",
    "# Проверяем, есть ли 'month_6' в столбце 'date'\n",
    "if 'month_6' in df['date'].values:\n",
    "    # Применяем интерполяцию ко всем числовым столбцам, исключая 'index_city_code'\n",
    "    df.loc[:, numeric_columns] = df.loc[:, numeric_columns].interpolate(method='linear')\n",
    "    \n",
    "    # Заполнение нечисловых столбцов, исключая 'index_city_code', вперёд\n",
    "    df.loc[:, non_numeric_columns] = df.loc[:, non_numeric_columns].fillna(method='ffill')\n",
    "else:\n",
    "    print('Упс, \"month_6\" не найден в столбце \"date\".')\n",
    "\n",
    "output_file_path = \"results/updated_test_data.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f'DataFrame сохранен в файл: {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7a1189-7d5c-4979-8c45-3bda7a65213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6679166666666667\n",
      "Log Loss: 0.9703665317602224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Загрузка данных из CSV файла\n",
    "df = pd.read_csv(\"results/updated_train_data.csv\")\n",
    "\n",
    "# Определение числовых и категориальных признаков\n",
    "numeric_features = ['balance_amt_avg', 'max_founderpres', 'sum_of_paym_2m', 'sum_of_paym_1y', \n",
    "                    'sum_a_oper_1m', 'sum_b_oper_1m', 'sum_c_oper_1m', 'sum_deb_d_oper_1m', 'sum_cred_d_oper_1m',\n",
    "                    'sum_deb_e_oper_1m', 'sum_cred_e_oper_1m', 'sum_deb_f_oper_1m', 'sum_cred_f_oper_1m',\n",
    "                    'sum_deb_g_oper_1m', 'sum_cred_g_oper_1m', 'sum_deb_h_oper_1m', 'sum_cred_h_oper_1m',\n",
    "                    'sum_a_oper_3m', 'sum_b_oper_3m', 'sum_c_oper_3m', 'sum_deb_d_oper_3m', 'sum_cred_d_oper_3m',\n",
    "                    'sum_deb_e_oper_3m', 'sum_cred_e_oper_3m', 'sum_deb_f_oper_3m', 'sum_cred_f_oper_3m',\n",
    "                    'sum_deb_g_oper_3m', 'sum_cred_g_oper_3m', 'sum_deb_h_oper_3m', 'sum_cred_h_oper_3m']\n",
    "categorical_features = ['start_cluster', 'channel_code', 'city_type', 'ogrn_month', 'ogrn_year', 'ft_registration_date', 'okved', 'segment']\n",
    "\n",
    "# Пайплайн предобработки\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создание и конфигурация модели логистической регрессии\n",
    "log_reg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=10000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Разделение данных\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df['end_cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение и предсказание\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "\n",
    "# Оценка\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Log Loss: {logloss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcbaa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8684799360032465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n",
    "    unnorm_weights = np.array([weights_dict[label] for label in labels])\n",
    "    weights = unnorm_weights / unnorm_weights.sum()\n",
    "    classes_roc_auc = roc_auc_score(y_true, y_pred, labels=labels,\n",
    "                                    multi_class=\"ovr\", average=None)\n",
    "    return sum(weights * classes_roc_auc)\n",
    "\n",
    "cluster_weights = pd.read_excel(\"Задание/cluster_weights.xlsx\").set_index(\"cluster\")\n",
    "weights_dict = cluster_weights[\"unnorm_weight\"].to_dict()\n",
    "\n",
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "weighted_roc_auc(y_test, y_pred_proba, log_reg.classes_, weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61791748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_with_mode(df):\n",
    "    # Получаем список столбцов с пропущенными значениями\n",
    "    columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    # Заменяем пропущенные значения на моду для каждого столбца\n",
    "    for column in columns_with_missing_values:\n",
    "        mode_value = df[column].mode()[0]  # Получаем моду столбца\n",
    "        df[column].fillna(mode_value, inplace=True)  # Заменяем пропущенные значения модой\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "645c3684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.82506554e-03, 3.85750432e-05, 1.40399353e-02, ...,\n",
       "        2.34921861e-03, 9.21443003e-01, 1.38961907e-05],\n",
       "       [1.02449871e-02, 5.46093109e-01, 4.39886335e-03, ...,\n",
       "        1.25310840e-03, 4.03561164e-01, 7.32896510e-05],\n",
       "       [5.64930853e-01, 1.73378921e-14, 3.94951514e-03, ...,\n",
       "        7.81195192e-02, 8.12498598e-02, 8.80301140e-07],\n",
       "       ...,\n",
       "       [1.79791263e-02, 2.06984084e-01, 8.47213947e-03, ...,\n",
       "        3.14374561e-03, 7.16515482e-01, 7.99096318e-05],\n",
       "       [2.22140495e-02, 7.41810207e-01, 2.50165663e-03, ...,\n",
       "        3.05611073e-03, 1.90108222e-01, 3.09388105e-04],\n",
       "       [1.03872036e-02, 4.56641043e-01, 5.28150014e-03, ...,\n",
       "        9.66652280e-04, 4.99868540e-01, 7.85152817e-05]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"results/updated_test_data.csv\")\n",
    "\n",
    "# Избавляемся в моделе от пустых значений, заполняя их модой и выбираем только 6 месяц\n",
    "test_df = replace_missing_with_mode(test_df)\n",
    "test_df = test_df[test_df.date == 'month_6']\n",
    "\n",
    "\n",
    "# Предсказываем значения\n",
    "# log_reg.predict(test_df)\n",
    "test_probabilities = log_reg.predict_proba(test_df)\n",
    "test_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e3c16df-5a3c-4278-b04b-6d11eac7054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>{other}</th>\n",
       "      <th>{}</th>\n",
       "      <th>{α, β}</th>\n",
       "      <th>{α, γ}</th>\n",
       "      <th>{α, δ}</th>\n",
       "      <th>{α, ε, η}</th>\n",
       "      <th>{α, ε, θ}</th>\n",
       "      <th>{α, ε, ψ}</th>\n",
       "      <th>{α, ε}</th>\n",
       "      <th>{α, η}</th>\n",
       "      <th>{α, θ}</th>\n",
       "      <th>{α, λ}</th>\n",
       "      <th>{α, μ}</th>\n",
       "      <th>{α, π}</th>\n",
       "      <th>{α, ψ}</th>\n",
       "      <th>{α}</th>\n",
       "      <th>{λ}</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009825</td>\n",
       "      <td>3.857504e-05</td>\n",
       "      <td>0.014040</td>\n",
       "      <td>0.027646</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.921443</td>\n",
       "      <td>1.389619e-05</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010245</td>\n",
       "      <td>5.460931e-01</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>7.328965e-05</td>\n",
       "      <td>200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.564931</td>\n",
       "      <td>1.733789e-14</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.189217</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.078120</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>8.803011e-07</td>\n",
       "      <td>200002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024838</td>\n",
       "      <td>4.710185e-01</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.033287</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.438744</td>\n",
       "      <td>5.534539e-05</td>\n",
       "      <td>200003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042701</td>\n",
       "      <td>5.777475e-01</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.265770</td>\n",
       "      <td>2.250203e-04</td>\n",
       "      <td>200004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.023574</td>\n",
       "      <td>1.994607e-01</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.691166</td>\n",
       "      <td>2.602203e-04</td>\n",
       "      <td>299995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.020333</td>\n",
       "      <td>1.989606e-01</td>\n",
       "      <td>0.020152</td>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.697120</td>\n",
       "      <td>2.954727e-04</td>\n",
       "      <td>299996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.017979</td>\n",
       "      <td>2.069841e-01</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.716515</td>\n",
       "      <td>7.990963e-05</td>\n",
       "      <td>299997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.022214</td>\n",
       "      <td>7.418102e-01</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.015857</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.190108</td>\n",
       "      <td>3.093881e-04</td>\n",
       "      <td>299998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.010387</td>\n",
       "      <td>4.566410e-01</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.499869</td>\n",
       "      <td>7.851528e-05</td>\n",
       "      <td>299999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        {other}            {}    {α, β}    {α, γ}    {α, δ}  {α, ε, η}  \\\n",
       "0      0.009825  3.857504e-05  0.014040  0.027646  0.003922   0.000415   \n",
       "1      0.010245  5.460931e-01  0.004399  0.010519  0.002681   0.000406   \n",
       "2      0.564931  1.733789e-14  0.003950  0.189217  0.012915   0.003325   \n",
       "3      0.024838  4.710185e-01  0.003606  0.009958  0.002600   0.000960   \n",
       "4      0.042701  5.777475e-01  0.002485  0.008398  0.001208   0.001603   \n",
       "...         ...           ...       ...       ...       ...        ...   \n",
       "99995  0.023574  1.994607e-01  0.017666  0.027742  0.008802   0.000275   \n",
       "99996  0.020333  1.989606e-01  0.020152  0.024191  0.010095   0.000300   \n",
       "99997  0.017979  2.069841e-01  0.008472  0.019465  0.004781   0.000353   \n",
       "99998  0.022214  7.418102e-01  0.002502  0.011207  0.001427   0.001104   \n",
       "99999  0.010387  4.566410e-01  0.005282  0.007984  0.001125   0.000419   \n",
       "\n",
       "       {α, ε, θ}  {α, ε, ψ}    {α, ε}    {α, η}    {α, θ}    {α, λ}    {α, μ}  \\\n",
       "0       0.000462   0.000199  0.003167  0.008965  0.005587  0.000312  0.001595   \n",
       "1       0.000487   0.000128  0.003497  0.011416  0.003362  0.000417  0.001421   \n",
       "2       0.004981   0.006748  0.023666  0.003765  0.023499  0.002003  0.001592   \n",
       "3       0.000459   0.000093  0.006418  0.033287  0.003878  0.000399  0.002937   \n",
       "4       0.000763   0.000303  0.002313  0.088135  0.004523  0.000416  0.001988   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "99995   0.002018   0.000273  0.007455  0.008702  0.006888  0.002320  0.001389   \n",
       "99996   0.001845   0.000302  0.006066  0.005166  0.008237  0.003034  0.001635   \n",
       "99997   0.000494   0.000189  0.005862  0.006863  0.006295  0.000456  0.002016   \n",
       "99998   0.000960   0.000494  0.002816  0.015857  0.004202  0.001009  0.000784   \n",
       "99999   0.000335   0.000109  0.003137  0.007545  0.004067  0.000774  0.001251   \n",
       "\n",
       "         {α, π}    {α, ψ}       {α}           {λ}      id  \n",
       "0      0.000018  0.002349  0.921443  1.389619e-05  200000  \n",
       "1      0.000041  0.001253  0.403561  7.328965e-05  200001  \n",
       "2      0.000039  0.078120  0.081250  8.803011e-07  200002  \n",
       "3      0.000036  0.000713  0.438744  5.534539e-05  200003  \n",
       "4      0.000117  0.001302  0.265770  2.250203e-04  200004  \n",
       "...         ...       ...       ...           ...     ...  \n",
       "99995  0.000093  0.001916  0.691166  2.602203e-04  299995  \n",
       "99996  0.000110  0.002156  0.697120  2.954727e-04  299996  \n",
       "99997  0.000053  0.003144  0.716515  7.990963e-05  299997  \n",
       "99998  0.000139  0.003056  0.190108  3.093881e-04  299998  \n",
       "99999  0.000032  0.000967  0.499869  7.851528e-05  299999  \n",
       "\n",
       "[100000 rows x 18 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание DataFrame с вероятностями перехода в каждый кластер для каждой строчки\n",
    "cluster_probabilities_df = pd.DataFrame(test_probabilities, columns=log_reg.classes_)\n",
    "\n",
    "# Добавление целевой переменной к DataFrame с вероятностями\n",
    "# cluster_probabilities_df = cluster_probabilities_df.reset_index(drop=True) # .astype(int)\n",
    "cluster_probabilities_df['id'] = test_df['id'].reset_index(drop=True)\n",
    "cluster_probabilities_df.to_csv('results/sample_submission.csv', encoding='utf-8', index=False)\n",
    "cluster_probabilities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51a32163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         200000\n",
       "5         200001\n",
       "8         200002\n",
       "11        200003\n",
       "13        200004\n",
       "           ...  \n",
       "290108    299995\n",
       "290111    299996\n",
       "290114    299997\n",
       "290116    299998\n",
       "290119    299999\n",
       "Name: id, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['id']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aad9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ae7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"Задание/train_data.pqt\")\n",
    "test_df = pd.read_parquet(\"Задание/test_data.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1093d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': ['start_cluster',\n",
       "  'channel_code',\n",
       "  'city_type',\n",
       "  'ogrn_month',\n",
       "  'ogrn_year',\n",
       "  'okved',\n",
       "  'segment'],\n",
       " 'nums': ['balance_amt_avg',\n",
       "  'ft_registration_date',\n",
       "  'max_founderpres',\n",
       "  'sum_of_paym_2m',\n",
       "  'sum_of_paym_1y',\n",
       "  'sum_a_oper_1m',\n",
       "  'sum_b_oper_1m',\n",
       "  'sum_c_oper_1m',\n",
       "  'sum_deb_d_oper_1m',\n",
       "  'sum_cred_d_oper_1m',\n",
       "  'sum_deb_e_oper_1m',\n",
       "  'sum_cred_e_oper_1m',\n",
       "  'sum_deb_f_oper_1m',\n",
       "  'sum_cred_f_oper_1m',\n",
       "  'sum_deb_g_oper_1m',\n",
       "  'sum_cred_g_oper_1m',\n",
       "  'sum_deb_h_oper_1m',\n",
       "  'sum_cred_h_oper_1m',\n",
       "  'sum_a_oper_3m',\n",
       "  'sum_b_oper_3m',\n",
       "  'sum_c_oper_3m',\n",
       "  'sum_deb_d_oper_3m',\n",
       "  'sum_cred_d_oper_3m',\n",
       "  'sum_deb_e_oper_3m',\n",
       "  'sum_cred_e_oper_3m',\n",
       "  'sum_deb_f_oper_3m',\n",
       "  'sum_cred_f_oper_3m',\n",
       "  'sum_deb_g_oper_3m',\n",
       "  'sum_cred_g_oper_3m',\n",
       "  'sum_deb_h_oper_3m',\n",
       "  'sum_cred_h_oper_3m']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'object': [],\n",
    "      'nums': []}\n",
    "for i in col:\n",
    "    if df[i].dtype.name != 'object':\n",
    "        dic['nums'].append(i)\n",
    "    else:\n",
    "        dic['object'].append(i)\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1943f",
   "metadata": {},
   "source": [
    "Записаны метрики, с которыми вышли лучшие результаты"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceb641df",
   "metadata": {},
   "source": [
    "['start_cluster', 'balance_amt_avg', 'channel_code', 'city_type', 'ogrn_month', 'ogrn_year', 'ft_registration_date', 'max_founderpres', 'okved', 'segment', 'sum_of_paym_2m', 'sum_of_paym_1y', 'sum_a_oper_1m', 'sum_b_oper_1m', 'sum_c_oper_1m', 'sum_deb_d_oper_1m', 'sum_cred_d_oper_1m', 'sum_deb_e_oper_1m', 'sum_cred_e_oper_1m', 'sum_deb_f_oper_1m', 'sum_cred_f_oper_1m', 'sum_deb_g_oper_1m', 'sum_cred_g_oper_1m', 'sum_deb_h_oper_1m', 'sum_cred_h_oper_1m', 'sum_a_oper_3m', 'sum_b_oper_3m', 'sum_c_oper_3m', 'sum_deb_d_oper_3m', 'sum_cred_d_oper_3m', 'sum_deb_e_oper_3m', 'sum_cred_e_oper_3m', 'sum_deb_f_oper_3m', 'sum_cred_f_oper_3m', 'sum_deb_g_oper_3m', 'sum_cred_g_oper_3m', 'sum_deb_h_oper_3m', 'sum_cred_h_oper_3m']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3a287",
   "metadata": {},
   "source": [
    "Пишем модель с разными входными параметрами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d73f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаем экземпляр: CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Обучаем модель: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of RandomForestClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 1.5 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Public\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.64051875 0.64190625 0.64153333 0.64928958 0.64056042 0.64366667\n",
      " 0.64340417 0.64534167 0.64269583        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.71382083 0.71381458 0.71376042 0.71350625 0.71335208 0.71372292\n",
      " 0.71256875 0.71348542 0.71346042        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72895    0.72992292 0.73065417 0.72795    0.72913125 0.7295375\n",
      " 0.72666875 0.72720208 0.72771042        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 41s\n",
      "Wall time: 1h 41min 23s\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Выбираем метрики для модели\n",
    "col = ['start_cluster', 'balance_amt_avg', 'channel_code', 'city_type', 'ogrn_month', 'ogrn_year', 'ft_registration_date', 'max_founderpres', 'okved', 'segment', 'sum_of_paym_2m', 'sum_of_paym_1y', 'sum_a_oper_1m', 'sum_b_oper_1m', 'sum_c_oper_1m', 'sum_deb_d_oper_1m', 'sum_cred_d_oper_1m', 'sum_deb_e_oper_1m', 'sum_cred_e_oper_1m', 'sum_deb_f_oper_1m', 'sum_cred_f_oper_1m', 'sum_deb_g_oper_1m', 'sum_cred_g_oper_1m', 'sum_deb_h_oper_1m', 'sum_cred_h_oper_1m', 'sum_a_oper_3m', 'sum_b_oper_3m', 'sum_c_oper_3m', 'sum_deb_d_oper_3m', 'sum_cred_d_oper_3m', 'sum_deb_e_oper_3m', 'sum_cred_e_oper_3m', 'sum_deb_f_oper_3m', 'sum_cred_f_oper_3m', 'sum_deb_g_oper_3m', 'sum_cred_g_oper_3m', 'sum_deb_h_oper_3m', 'sum_cred_h_oper_3m']\n",
    "# col = ['start_cluster'] # Тестовая (чем меньше метрик, тем быстрее модель)\n",
    "\n",
    "# Разделяем данные на признаки (X) и целевую переменную (y)\n",
    "y = df['end_cluster']  # целевая переменная\n",
    "\n",
    "X = pd.DataFrame()\n",
    "for i in col:\n",
    "    if df[i].dtype.name != 'object':\n",
    "        X[i]=df[i].copy()\n",
    "        X.loc[X[i].isna(), i]=X[i].median()\n",
    "    else:\n",
    "        X[i]=pd.factorize(df[i])[0]\n",
    "        \n",
    "        \n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем и Обучаем модель случайного леса\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Перебираем разные данные к модели\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [20, 25, 30],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Создаем экземпляр GridSearchCV\n",
    "print('Создаем экземпляр:', end=' ')\n",
    "%time model = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с использованием GridSearchCV\n",
    "print('Обучаем модель:', end=' ')\n",
    "%time model.fit(X_train, y_train)\n",
    "\n",
    "### Штука не быстрая, придётся подождать\n",
    "\n",
    "# {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "# {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "# Выводим лучшие параметры\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca20438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2671, 'start_cluster'],\n",
       " [0.0623, 'sum_cred_e_oper_3m'],\n",
       " [0.0549, 'sum_deb_e_oper_3m'],\n",
       " [0.0532, 'balance_amt_avg'],\n",
       " [0.0512, 'sum_deb_e_oper_1m'],\n",
       " [0.0407, 'sum_cred_e_oper_1m'],\n",
       " [0.0386, 'okved'],\n",
       " [0.032, 'ft_registration_date'],\n",
       " [0.0316, 'sum_of_paym_1y'],\n",
       " [0.03, 'sum_cred_h_oper_3m'],\n",
       " [0.0264, 'max_founderpres'],\n",
       " [0.0254, 'sum_deb_h_oper_3m'],\n",
       " [0.0248, 'sum_of_paym_2m'],\n",
       " [0.0204, 'channel_code'],\n",
       " [0.0196, 'sum_deb_g_oper_3m'],\n",
       " [0.0189, 'ogrn_month'],\n",
       " [0.0182, 'sum_deb_h_oper_1m'],\n",
       " [0.0175, 'sum_deb_g_oper_1m'],\n",
       " [0.0175, 'sum_cred_h_oper_1m'],\n",
       " [0.0162, 'ogrn_year'],\n",
       " [0.0161, 'sum_deb_f_oper_3m'],\n",
       " [0.0115, 'sum_deb_d_oper_3m'],\n",
       " [0.0112, 'sum_deb_f_oper_1m'],\n",
       " [0.0103, 'segment'],\n",
       " [0.0101, 'sum_cred_g_oper_3m'],\n",
       " [0.0089, 'sum_deb_d_oper_1m'],\n",
       " [0.0088, 'sum_b_oper_3m'],\n",
       " [0.0087, 'city_type'],\n",
       " [0.0082, 'sum_a_oper_3m'],\n",
       " [0.0076, 'sum_c_oper_3m'],\n",
       " [0.0062, 'sum_cred_g_oper_1m'],\n",
       " [0.0056, 'sum_c_oper_1m'],\n",
       " [0.0051, 'sum_a_oper_1m'],\n",
       " [0.0043, 'sum_b_oper_1m'],\n",
       " [0.0036, 'sum_cred_f_oper_3m'],\n",
       " [0.0031, 'sum_cred_d_oper_3m'],\n",
       " [0.0021, 'sum_cred_f_oper_1m'],\n",
       " [0.002, 'sum_cred_d_oper_1m']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = RandomForestClassifier(max_depth = 10, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 100)\n",
    "model = RandomForestClassifier(**model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Считаем значимость метрик\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "ar_f=[]\n",
    "for f, idx in enumerate(indices):\n",
    "    ar_f.append([round(importances[idx],4), col[idx]])\n",
    "ar_f.sort(reverse=True)\n",
    "\n",
    "# Предсказываем значения на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцениваем качество модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "ar_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f84e5",
   "metadata": {},
   "source": [
    "Считаем точность модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118cbf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337127862450603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n",
    "    unnorm_weights = np.array([weights_dict[label] for label in labels])\n",
    "    weights = unnorm_weights / unnorm_weights.sum()\n",
    "    classes_roc_auc = roc_auc_score(y_true, y_pred, labels=labels,\n",
    "                                    multi_class=\"ovr\", average=None)\n",
    "    return sum(weights * classes_roc_auc)\n",
    "\n",
    "cluster_weights = pd.read_excel(\"Задание/cluster_weights.xlsx\").set_index(\"cluster\")\n",
    "weights_dict = cluster_weights[\"unnorm_weight\"].to_dict()\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "weighted_roc_auc(y_test, y_pred_proba, model.classes_, weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a9966",
   "metadata": {},
   "source": [
    "Считаем модель на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8aeb3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.42382083e-01, 1.06225132e-03, 5.36121319e-03, ...,\n",
       "        4.85790126e-04, 6.60724878e-02, 0.00000000e+00],\n",
       "       [6.28135732e-01, 4.30179563e-04, 5.77274543e-03, ...,\n",
       "        8.35353408e-04, 3.78903922e-02, 0.00000000e+00],\n",
       "       [3.66641843e-01, 4.13574073e-04, 5.82440764e-03, ...,\n",
       "        5.79829013e-03, 7.46007732e-02, 0.00000000e+00],\n",
       "       ...,\n",
       "       [7.49746653e-03, 8.00228779e-01, 1.35959141e-03, ...,\n",
       "        1.10800815e-03, 1.76068139e-01, 1.58174288e-04],\n",
       "       [7.51342302e-03, 8.00263443e-01, 1.37668543e-03, ...,\n",
       "        1.06242930e-03, 1.75967936e-01, 1.92362322e-04],\n",
       "       [1.06708897e-02, 4.52558228e-01, 2.77854936e-03, ...,\n",
       "        6.41277754e-04, 5.13692464e-01, 6.40466195e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные из тестовой метрики\n",
    "test_df = test_df[test_df.date == 'month_6']\n",
    "test_df[\"start_cluster\"] = df[\"start_cluster\"].mode()[0]\n",
    "\n",
    "\n",
    "X = pd.DataFrame()\n",
    "for i in col:\n",
    "    if df[i].dtype.name != 'object':\n",
    "        X[i]=df[i].copy()\n",
    "        X.loc[X[i].isna(), i]=X[i].median()\n",
    "    else:\n",
    "        X[i]=pd.factorize(df[i])[0]\n",
    "\n",
    "# Предсказываем значения\n",
    "model.predict(X)\n",
    "test_probabilities = model.predict_proba(X)\n",
    "\n",
    "test_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39fe42c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>{other}</th>\n",
       "      <th>{}</th>\n",
       "      <th>{α, β}</th>\n",
       "      <th>{α, γ}</th>\n",
       "      <th>{α, δ}</th>\n",
       "      <th>{α, ε, η}</th>\n",
       "      <th>{α, ε, θ}</th>\n",
       "      <th>{α, ε, ψ}</th>\n",
       "      <th>{α, ε}</th>\n",
       "      <th>{α, η}</th>\n",
       "      <th>{α, θ}</th>\n",
       "      <th>{α, λ}</th>\n",
       "      <th>{α, μ}</th>\n",
       "      <th>{α, π}</th>\n",
       "      <th>{α, ψ}</th>\n",
       "      <th>{α}</th>\n",
       "      <th>{λ}</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366642</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.074601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.849161</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.069449</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.028880</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.012550</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.927396</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>200002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023534</td>\n",
       "      <td>0.438532</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>200003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.023827</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.832943</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>200004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059161</td>\n",
       "      <td>0.223484</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.038401</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.539941</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>200005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145756</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.785701</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.055691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015607</td>\n",
       "      <td>0.161054</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.794308</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>200007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067856</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>0.680223</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.214338</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>200008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    {other}        {}    {α, β}    {α, γ}    {α, δ}  {α, ε, η}  {α, ε, θ}  \\\n",
       "0  0.366642  0.000414  0.005824  0.514037  0.005490   0.000000   0.000635   \n",
       "1  0.849161  0.001246  0.001523  0.069449  0.001896   0.006253   0.000981   \n",
       "2  0.003978  0.028880  0.010923  0.012550  0.001583   0.000102   0.000261   \n",
       "3  0.023534  0.438532  0.001577  0.005899  0.001206   0.000293   0.000349   \n",
       "4  0.025023  0.015385  0.023827  0.034737  0.009075   0.000854   0.001013   \n",
       "5  0.059161  0.223484  0.013533  0.038401  0.003398   0.002936   0.001081   \n",
       "6  0.145756  0.003495  0.000895  0.785701  0.001622   0.000000   0.000038   \n",
       "7  0.015607  0.161054  0.005328  0.005616  0.001159   0.000164   0.000256   \n",
       "8  0.067856  0.016645  0.007476  0.680223  0.000587   0.000065   0.000252   \n",
       "\n",
       "   {α, ε, ψ}    {α, ε}    {α, η}    {α, θ}    {α, λ}    {α, μ}    {α, π}  \\\n",
       "0   0.000000  0.014658  0.000387  0.007892  0.003551  0.000071  0.000000   \n",
       "1   0.000075  0.010275  0.019637  0.003433  0.000635  0.002128  0.000000   \n",
       "2   0.000000  0.002880  0.005221  0.004486  0.000249  0.001142  0.000000   \n",
       "3   0.000019  0.001416  0.009176  0.001197  0.000174  0.000988  0.000006   \n",
       "4   0.000599  0.019613  0.015664  0.010030  0.002269  0.006770  0.000022   \n",
       "5   0.000213  0.006174  0.093914  0.010172  0.000995  0.003560  0.000000   \n",
       "6   0.000427  0.001940  0.000169  0.001222  0.000000  0.000019  0.000000   \n",
       "7   0.000090  0.002540  0.008879  0.002081  0.000213  0.001309  0.000000   \n",
       "8   0.000206  0.003268  0.001700  0.005148  0.000982  0.000476  0.000000   \n",
       "\n",
       "     {α, ψ}       {α}       {λ}        id  \n",
       "0  0.005798  0.074601  0.000000  200000.0  \n",
       "1  0.007809  0.025498  0.000000  200001.0  \n",
       "2  0.000342  0.927396  0.000006  200002.0  \n",
       "3  0.000577  0.514894  0.000163  200003.0  \n",
       "4  0.002169  0.832943  0.000008  200004.0  \n",
       "5  0.002867  0.539941  0.000171  200005.0  \n",
       "6  0.003023  0.055691  0.000000  200006.0  \n",
       "7  0.001104  0.794308  0.000292  200007.0  \n",
       "8  0.000654  0.214338  0.000125  200008.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание DataFrame с вероятностями перехода в каждый кластер для каждой строчки\n",
    "cluster_probabilities_df = pd.DataFrame(test_probabilities, columns=model.classes_)\n",
    "\n",
    "# Добавление целевой переменной к DataFrame с вероятностями\n",
    "cluster_probabilities_df['id'] = test_df['id']\n",
    "cluster_probabilities_df = cluster_probabilities_df.dropna(subset=['id']).reset_index(drop=True) # .astype(int)\n",
    "cluster_probabilities_df.to_csv('results/sample_submission.csv', encoding='utf-8', index=False)\n",
    "cluster_probabilities_df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec26c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333833333333334"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356afa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  2.0  1.0\n",
      "1  2.0  2.0  1.0\n",
      "2  3.0  3.0  3.0\n",
      "3  1.0  4.0  1.0\n",
      "4  5.0  5.0  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def replace_missing_with_mode(df):\n",
    "    # Получаем список столбцов с пропущенными значениями\n",
    "    columns_with_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    # Заменяем пропущенные значения на моду для каждого столбца\n",
    "    for column in columns_with_missing_values:\n",
    "        mode_value = df[column].mode()[0]  # Получаем моду столбца\n",
    "        df[column].fillna(mode_value, inplace=True)  # Заменяем пропущенные значения модой\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Пример использования функции\n",
    "# Создаем DataFrame для демонстрации\n",
    "data = {'A': [1, 2, 3, None, 5],\n",
    "        'B': [None, 2, 3, 4, 5],\n",
    "        'C': [1, None, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Заменяем пропущенные значения на моду\n",
    "df = replace_missing_with_mode(df)\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
